## InterpretML from Microsoft
[InterpretML](https://interpret.ml/)
- InterpretML is an open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof.
- With this package, you can train interpretable Glassbox models and explain Blackbox systems.
- InterpretML helps you understand your model's global behavior, or understand the reasons behind individual predictions.

## Why InterpretML?

**Model Interpretability**

Model interpretability helps developers, data scientists and business stakeholders in the organization gain a comprehensive understanding of their machine learning models. It can also be used to debug models, explain predictions and enable auditing to meet compliance with regulatory requirements.

1. Ease of use
Access state-of-the-art interpretability techniques through an open unified API set and rich visualizations.

2. Flexible
Understand models using a wide range of explainers and techniques using interactive visuals. Choose your algorithm and easily experiment with combinations of algorithms.

3. Comprehensive capabilities
Explore model attributes such as performance, global and local features and local features and compare multiple models simultaneously. Run what-if analysis as you manipulate data and view the impact on the model.

## Types of Models Supported

1. Glass-Box
Glass-Box models are interpretable due to their structure. Examples include: Explainable Boosting Machines (EBM), Linear models, and decision trees.

Glass-box models produce lossless explanation and are editable by domain experts.

2. Black-Box
Black models are challenging to understand, for example deep neural networks. Black-box explainers can analysis the relationship between input features and output predictions to interpret models. Example include `LIME` and `SHAP`.

## Wide Variety of Techniques

1. Global
Explore overall models behavior and find top features affecting model predictions using global feature importance

2. Local
Explain an individual prediction and find features contributing to it using local feature importance.

3. Subset
Explain a subset of predictions using group feature importance.

4. Feature Impact
See how changes to input feature impact predictions with techniques like what-if analysis.

## What You Can Do With InterpretML

1. Explore Your Data and Model performance
- Understand how model changes for different subsets of data and compare multiple models
- Explore models errors
- Analyze dataset statistics and distributions

2. Gain Model Understanding
- Explore global and local explanations
- Filter data to observe global and local feature importance.
- Run what-if analysis to see how model explanations change if you edit datapoints' features.

### Supported Techniques

|Interpretability Technique | Type|
|---------------------|---|
|Explainable Boosting | glassbox model|
|Decision Tree| glassbox model|
|Desision Rule Regression | glassbox model|
|SHAP Kernel Explainer | blackbox explainer |
|LIME | blackbox explainer|
|Morris Sensitivity Analysis | blackbox explainer |
|Partial Dependence | blackbox expaliner|